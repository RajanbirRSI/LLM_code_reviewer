name: Automated Code Review (Bash Version)

on:
  workflow_dispatch:
  push:
    branches-ignore:
      - main
  pull_request:
    types: [opened, synchronize, reopened]

jobs:
  code-review:
    runs-on: self-hosted
    
    # Set default shell to bash for all steps
    defaults:
      run:
        shell: bash
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Check powershell is working
        shell: pwsh
        run: |
         pwsh -Command "Write-Host 'PowerShell Core is working!'"
         
      - name: Check Python
        shell: pwsh  # Use Bash
        run: |
          python --version
          pip --version

      - name: Install dependencies
        shell: pwsh
        run: |
          if (Test-Path "requirements.txt") {
            pip install -r requirements.txt
          }
          pip install requests PyGithub

      - name: Check Ollama service
        shell: pwsh
        run: |
          try {
            ollama ps
            Write-Host "Ollama is running"
          } catch {
            Write-Host "Starting Ollama service..."
            Start-Process "ollama" -ArgumentList "serve" -WindowStyle Hidden
            Start-Sleep 10
            ollama ps
          }

      - name: Ensure required models are available
        shell: pwsh
        run: |
          $models = ollama list
          if ($models -notmatch "mistral") {
            Write-Host "Pulling Mistral model..."
            ollama pull mistral
          }

      - name: Run automated code reviewer
        id: code-review
        shell: bash  # Your original bash syntax works here
        run: |
          echo "=== Running Code Review ==="
          
          # Run the Python script with explicit error handling
          set +e  # Don't exit on error immediately
          python automated_code_reviewer.py > review_output.txt 2>&1
          python_exit_code=$?
          set -e  # Re-enable exit on error
          
          echo "Python script exit code: $python_exit_code"
          
          # Always show what was captured
          if [ -f "review_output.txt" ]; then
            echo "=== Review Output Content ==="
            cat review_output.txt
            echo "=== End of Review Output ==="
          else
            echo "‚ùå Review output file was not created!"
            exit 1
          fi
          
          # Check if Python script failed
          if [ $python_exit_code -ne 0 ]; then
            echo "‚ùå Python script failed with exit code: $python_exit_code"
            # Don't exit here, try to extract score anyway
          fi
          
          # Extract score using compatible grep (without -P flag)
          # Try multiple patterns to match different output formats
          SCORE=""
          
          # Pattern 1: "Overall Score: 85"
          SCORE=$(grep -i "overall score" review_output.txt | grep -o '[0-9]\+' | head -1 || echo "")
          
          # Pattern 2: "Score: 85" 
          if [ -z "$SCORE" ]; then
            SCORE=$(grep -i "^score" review_output.txt | grep -o '[0-9]\+' | head -1 || echo "")
          fi
          
          # Pattern 3: Any line ending with "/100"
          if [ -z "$SCORE" ]; then
            SCORE=$(grep -o '[0-9]\+/100' review_output.txt | grep -o '^[0-9]\+' | head -1 || echo "")
          fi
          
          # Pattern 4: Any number between 0-100 (last resort)
          if [ -z "$SCORE" ]; then
            SCORE=$(grep -o '\b[0-9]\{1,3\}\b' review_output.txt | head -1 || echo "")
            # Validate it's a reasonable score (0-100)
            if [ ! -z "$SCORE" ] && ([ "$SCORE" -lt 0 ] || [ "$SCORE" -gt 100 ]); then
              SCORE=""
            fi
          fi
          
          # Default score if nothing found
          if [ -z "$SCORE" ]; then
            echo "‚ö†Ô∏è Could not extract score from output, defaulting to 0"
            SCORE=0
          else
            echo "‚úÖ Extracted Score: $SCORE"
          fi
          
          # Set outputs for next steps
          echo "score=$SCORE" >> $GITHUB_OUTPUT
          
          # Determine pass/fail
          if [ "$SCORE" -ge 75 ]; then
            echo "passed=true" >> $GITHUB_OUTPUT
            echo "‚úÖ Review Passed: YES (Score: $SCORE/100)"
          else
            echo "passed=false" >> $GITHUB_OUTPUT
            echo "‚ùå Review Failed: NO (Score: $SCORE/100)"
          fi

      - name: Debug outputs
        shell: bash
        run: |
          echo "=== Debug Outputs ==="
          echo "Score output: ${{ steps.code-review.outputs.score }}"
          echo "Passed output: ${{ steps.code-review.outputs.passed }}"
      # Rest of the steps remain the same as the PowerShell version
       - name: Comment on PR
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v7
      with:
        script: |
          const score = ${{ steps.code-review.outputs.score }};
          const passed = ${{ steps.code-review.outputs.passed }};
          const shouldMerge = ${{ steps.check-merge.outputs.should-merge }};
          
          const status = passed ? '‚úÖ PASSED' : '‚ùå FAILED';
          const mergeStatus = shouldMerge ? 'üîÑ Auto-merge enabled' : '‚è∏Ô∏è Manual review required';
          
          const comment = `## ü§ñ Automated Code Review Results
          
          **Score:** ${score}/100
          **Status:** ${status}
          **Action:** ${mergeStatus}
          
          ${passed ? 
            '‚úÖ Your code meets our quality standards!' : 
            '‚ùå Please address the issues and push changes for re-review.'
          }
          
          ---
          *Minimum score required: 75/100*`;
          
          github.rest.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: comment
          });

  auto-merge:
    needs: code-review
    runs-on: ubuntu-latest
    if: needs.code-review.outputs.should-merge == 'true'
    permissions:
      contents: write
      pull-requests: write
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Auto-merge PR
      uses: actions/github-script@v7
      with:
        script: |
          // Fixed output reference
          const score = ${{ needs.code-review.outputs.score }};
          
          console.log(`Attempting to merge PR with score: ${score}/100`);
          
          try {
            await github.rest.pulls.merge({
              owner: context.repo.owner,
              repo: context.repo.repo,
              pull_number: context.issue.number,
              commit_title: `Auto-merge: Code review passed (${score}/100)`,
              commit_message: `Automated merge after successful code review.\nScore: ${score}/100\nThreshold: 75/100`,
              merge_method: 'squash'
            });
            
            console.log('‚úÖ PR merged successfully!');
            
          } catch (error) {
            console.error('‚ùå Failed to merge PR:', error.message);
            
            await github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## ‚ö†Ô∏è Auto-merge Failed
              
              The code review passed (${score}/100), but automatic merging failed.
              Please merge manually or check for conflicts.
              
              **Error:** ${error.message}`
            });
          }

  notify-failure:
    needs: code-review
    runs-on: ubuntu-latest
    if: needs.code-review.outputs.passed == 'false'
    
    steps:
    - name: Notify review failure
      run: |
        echo "‚ùå Code review failed"
        echo "Score: ${{ needs.code-review.outputs.review-score }}/100"
        echo "Minimum required: 75/100"
        echo "Manual review and fixes required before merge"

      # - name: Upload review artifacts
      #   if: always()
      #   uses: actions/upload-artifact@v4
      #   with:
      #     name: code-review-results
      #     path: |
      #       review_output.txt
      #       *.log
      #     retention-days: 30
