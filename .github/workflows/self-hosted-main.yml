name: Automated Code Review (Bash Version)

on:
  workflow_dispatch:
  push:
    branches-ignore:
      - main
  pull_request:
    types: [opened, synchronize, reopened]

jobs:
  code-review:
    runs-on: self-hosted
    
    # Set default shell to bash for all steps
    defaults:
      run:
        shell: bash
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Check powershell is working
        shell: pwsh
        run: |
         pwsh -Command "Write-Host 'PowerShell Core is working!'"
         
      - name: Check Python
        shell: pwsh  # Use Bash
        run: |
          python --version
          pip --version

      - name: Install dependencies
        shell: pwsh
        run: |
          if (Test-Path "requirements.txt") {
            pip install -r requirements.txt
          }
          pip install requests PyGithub

      - name: Check Ollama service
        shell: pwsh
        run: |
          try {
            ollama ps
            Write-Host "Ollama is running"
          } catch {
            Write-Host "Starting Ollama service..."
            Start-Process "ollama" -ArgumentList "serve" -WindowStyle Hidden
            Start-Sleep 10
            ollama ps
          }

      - name: Ensure required models are available
        shell: pwsh
        run: |
          $models = ollama list
          # if ($models -notmatch "mistral") {
          #   Write-Host "Pulling Mistral model..."
          #   ollama pull mistral
          # }
          if ($models -notmatch "hf.co/bartowski/Llama-3.2-3B-Instruct-GGUF:IQ3_M") {
            Write-Host "Pulling Llama 3.2 quantized model..."
            ollama pull hf.co/bartowski/Llama-3.2-3B-Instruct-GGUF:IQ3_M 
          }

      - name: Run automated code reviewer
        id: code-review
        shell: bash  # Your original bash syntax works here
        run: |
          echo "========================= Running Code Review =============================="
          
          # Run the Python script with explicit error handling
          set +e  # Don't exit on error immediately
          python automated_code_reviewer.py > review_output.txt 2>&1
          python_exit_code=$?
          set -e  # Re-enable exit on error
          
          echo "Python script exit code: $python_exit_code"
          
          # Always show what was captured
          if [ -f "review_output.txt" ]; then
            echo "========================= Review Output Content =============================="
            cat review_output.txt
            echo "========================= End of Review Output "=========================
          else
            echo "Review output file was not created!"
            exit 1
          fi
          
          # Check if Python script failed
          if [ $python_exit_code -ne 0 ]; then
            echo "Python script failed with exit code: $python_exit_code"
            # Don't exit here, try to extract score anyway
          fi

          # # Extract score from output
          # #SCORE=$(grep -o "Score: [0-9]\+/100" review_output.txt | grep -o "[0-9]\+" | tail -1)
          # #SCORE=$(grep -oE "Score: [0-9]+/100" review_output.txt | grep -oE "[0-9]+" | head -1)
          # SCORE=$(grep -oE "\b[0-9]+/100\b" review_output.txt | cut -d'/' -f1 | head -1)

          # Extract score from output using only grep -o (no -E)
          SCORE=$(grep -o "[0-9]\{1,3\}/100" review_output.txt | cut -d'/' -f1 | head -1)
          
          # Default score if nothing found
          if [ -z "$SCORE" ]; then
            echo " /!\ Could not extract score from output, defaulting to 0"
            SCORE=0
          else
            echo "Extracted Score: $SCORE"
          fi
            
            # Set outputs for next steps
            echo "score=$SCORE" >> $GITHUB_OUTPUT
          
          # Determine pass/fail
          if [ "$SCORE" -ge 75 ]; then
            echo "passed=true" >> $GITHUB_OUTPUT
            echo "Review Passed: YES (Score: $SCORE/100)"
          else
            echo "passed=false" >> $GITHUB_OUTPUT
            echo "Review Failed: NO (Score: $SCORE/100)"
          fi

      - name: Debug outputs
        shell: bash
        run: |
          echo "=== Debug Outputs ==="
          echo "Score output: ${{ steps.code-review.outputs.score }}"
          echo "Passed output: ${{ steps.code-review.outputs.passed }}"

      - name: Comment on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const score = ${{ steps.code-review.outputs.score }};
            const passed = ${{ steps.code-review.outputs.passed }};
            const shouldMerge = ${{ steps.check-merge.outputs.should-merge }};
            
            const status = passed ? '‚úÖ PASSED' : '‚ùå FAILED';
            const mergeStatus = shouldMerge ? 'üîÑ Auto-merge enabled' : '‚è∏Ô∏è Manual review required';
            
            const comment = `## ü§ñ Automated Code Review Results
            
            **Score:** ${score}/100
            **Status:** ${status}
            **Action:** ${mergeStatus}
            
            ${passed ? 
              '‚úÖ Your code meets our quality standards!' : 
              '‚ùå Please address the issues and push changes for re-review.'
            }
            
            ---
            *Minimum score required: 75/100*`;
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });

  auto-merge:
    needs: code-review
    runs-on: self-hosted
    if: needs.code-review.outputs.should-merge == 'true'
    permissions:
      contents: write
      pull-requests: write
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Auto-merge PR
      uses: actions/github-script@v7
      with:
        script: |
          // Fixed output reference
          const score = ${{ needs.code-review.outputs.score }};
          
          console.log(`Attempting to merge PR with score: ${score}/100`);
          
          try {
            await github.rest.pulls.merge({
              owner: context.repo.owner,
              repo: context.repo.repo,
              pull_number: context.issue.number,
              commit_title: `Auto-merge: Code review passed (${score}/100)`,
              commit_message: `Automated merge after successful code review.\nScore: ${score}/100\nThreshold: 75/100`,
              merge_method: 'squash'
            });
            
            console.log('‚úÖ PR merged successfully!');
            
          } catch (error) {
            console.error('‚ùå Failed to merge PR:', error.message);
            
            await github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: `## ‚ö†Ô∏è Auto-merge Failed
              
              The code review passed (${score}/100), but automatic merging failed.
              Please merge manually or check for conflicts.
              
              **Error:** ${error.message}`
            });
          }

  notify-failure:
    needs: code-review
    runs-on: self-hosted
    if: needs.code-review.outputs.passed == 'false'
    
    steps:
    - name: Notify review failure
      run: |
        echo "‚ùå Code review failed"
        echo "Score: ${{ needs.code-review.outputs.review-score }}/100"
        echo "Minimum required: 75/100"
        echo "Manual review and fixes required before merge"

      # - name: Upload review artifacts
      #   if: always()
      #   uses: actions/upload-artifact@v4
      #   with:
      #     name: code-review-results
      #     path: |
      #       review_output.txt
      #       *.log
      #     retention-days: 30
